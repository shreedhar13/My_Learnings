{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff20b9f3",
   "metadata": {},
   "source": [
    "# Graduate Admision prediction,,,ie;based on below given marks range if new students come then how much probability is there of selection of that student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed0060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.GRE Scores ( out of 340 )\n",
    "# 2.TOEFL Scores ( out of 120 )\n",
    "# 3.University Rating ( out of 5 )\n",
    "# 4.Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n",
    "# 5.Undergraduate GPA ( out of 10 )\n",
    "# 6.Research Experience ( either 0 or 1 )\n",
    "# 7.Chance of Admit ( ranging from 0 to 1 )#ie; 0 to 1 there are many no,,so continuous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf2847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ece13ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"D:\\DEEP_LEARNING\\4_Admission_Predict_Ver1.1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a696cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#no any missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a570e721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n",
    "#all rows are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018e85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#but scaling is must before training it on ANN model\n",
    "#bcz,,all values come in one range thus weights(coefficient) and bias(intercept) converges easily and fastly\n",
    "#converges means,,best value of w and b is calculated ,such that on unseen data testing accuracy is high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2fe94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use Min-MAX scaler,,,bcz we know upper bound and lower bound of each column\n",
    "#ie;GRE score has upper bound 340\n",
    "# 2.TOEFL Scores ( out of 120 )\n",
    "# 3.University Rating ( out of 5 )\n",
    "# 4.Statement of Purpose and Letter of Recommendation Strength ( out of 5 )\n",
    "# 5.Undergraduate GPA ( out of 10 )\n",
    "# 6.Research Experience ( either 0 or 1 )\n",
    "#and lower bound for all is 0,,,,,\n",
    "#if this is not the case then use StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9fc7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)#doesnt effect on prediction/selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2417e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12dd7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7014147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61c5b511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 7), (400,), (100, 7), (100,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aa1f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)#bcz we are using same parameters which are calculated for scaling X_train,,so that both should compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42949e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73d4a2",
   "metadata": {},
   "source": [
    "# TRAINING ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65f9cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073e9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(1,activation='linear'))#NOTE-->whenever u are dealing with regression problem  ,o/p layers has 1 node with\n",
    "#activation function as 'linear'...only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be2ca261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64 (256.00 Byte)\n",
      "Trainable params: 64 (256.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a94d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense (Dense)               (None, 7)                 56  ->H.L 1      \n",
    "                                                                 \n",
    "#  dense_1 (Dense)             (None, 1)                 8  ->o/p layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77bc4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "661bfdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.1966 - val_loss: 1.2570\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0349 - val_loss: 1.0984\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9080 - val_loss: 0.9748\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8083 - val_loss: 0.8729\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7275 - val_loss: 0.7908\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6609 - val_loss: 0.7268\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6731\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5706 - val_loss: 0.6292\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5370 - val_loss: 0.5919\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5090 - val_loss: 0.5598\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=10,validation_split=0.2)\n",
    "#for tracking accuracy use metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c1865",
   "metadata": {},
   "source": [
    "# predicting/testing ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87d745aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07295094],\n",
       "       [ 0.09172656],\n",
       "       [-0.2261987 ],\n",
       "       [ 0.09569117],\n",
       "       [ 0.09641751],\n",
       "       [ 0.09327066],\n",
       "       [ 0.09411404],\n",
       "       [ 0.09639584],\n",
       "       [ 0.09551408],\n",
       "       [ 0.09601158],\n",
       "       [ 0.09980716],\n",
       "       [ 0.09111813],\n",
       "       [ 0.09191182],\n",
       "       [-0.10901914],\n",
       "       [ 0.09483288],\n",
       "       [ 0.09725218],\n",
       "       [-0.12182181],\n",
       "       [-0.11435734],\n",
       "       [ 0.0945207 ],\n",
       "       [-0.02208275],\n",
       "       [ 0.09574518],\n",
       "       [ 0.09609118],\n",
       "       [ 0.09734136],\n",
       "       [ 0.09111813],\n",
       "       [-0.11975131],\n",
       "       [ 0.05551418],\n",
       "       [ 0.09780943],\n",
       "       [-0.05862244],\n",
       "       [ 0.09649522],\n",
       "       [ 0.09421863],\n",
       "       [-0.07595422],\n",
       "       [ 0.09646597],\n",
       "       [ 0.0511828 ],\n",
       "       [ 0.09838393],\n",
       "       [-0.08083668],\n",
       "       [ 0.05771355],\n",
       "       [-0.03806599],\n",
       "       [ 0.03910169],\n",
       "       [ 0.01634982],\n",
       "       [ 0.09652278],\n",
       "       [-0.02941062],\n",
       "       [ 0.09359708],\n",
       "       [ 0.09424347],\n",
       "       [ 0.09839945],\n",
       "       [ 0.09407162],\n",
       "       [-0.04166859],\n",
       "       [-0.05801598],\n",
       "       [-0.1792675 ],\n",
       "       [ 0.09111813],\n",
       "       [-0.06133672],\n",
       "       [ 0.09685174],\n",
       "       [ 0.0990293 ],\n",
       "       [ 0.09429519],\n",
       "       [ 0.09126128],\n",
       "       [-0.06221064],\n",
       "       [ 0.09206831],\n",
       "       [ 0.09466683],\n",
       "       [ 0.04443877],\n",
       "       [ 0.09320286],\n",
       "       [ 0.09267247],\n",
       "       [-0.03947224],\n",
       "       [-0.26246223],\n",
       "       [ 0.09858026],\n",
       "       [ 0.09555669],\n",
       "       [ 0.09959376],\n",
       "       [ 0.05341618],\n",
       "       [ 0.09478449],\n",
       "       [ 0.09261774],\n",
       "       [ 0.10090522],\n",
       "       [-0.03657027],\n",
       "       [ 0.05625704],\n",
       "       [-0.07903037],\n",
       "       [-0.00747058],\n",
       "       [ 0.07778687],\n",
       "       [ 0.09734413],\n",
       "       [-0.11001558],\n",
       "       [ 0.09583284],\n",
       "       [ 0.09721626],\n",
       "       [ 0.09222002],\n",
       "       [ 0.0932737 ],\n",
       "       [ 0.03216546],\n",
       "       [-0.07924504],\n",
       "       [ 0.09555379],\n",
       "       [ 0.09635983],\n",
       "       [-0.28356615],\n",
       "       [ 0.06488097],\n",
       "       [ 0.09584174],\n",
       "       [ 0.09481773],\n",
       "       [-0.156609  ],\n",
       "       [-0.05688976],\n",
       "       [-0.22008777],\n",
       "       [ 0.09656326],\n",
       "       [-0.15617797],\n",
       "       [ 0.09343478],\n",
       "       [ 0.09210987],\n",
       "       [ 0.09653895],\n",
       "       [ 0.09422444],\n",
       "       [-0.1253655 ],\n",
       "       [-0.04703794],\n",
       "       [-0.19662112]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdae3062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304    0.62\n",
       "340    0.75\n",
       "47     0.89\n",
       "67     0.57\n",
       "479    0.79\n",
       "       ... \n",
       "11     0.84\n",
       "192    0.86\n",
       "92     0.34\n",
       "221    0.75\n",
       "110    0.61\n",
       "Name: Chance of Admit , Length: 100, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc2ab74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 1), (100,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39264b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.192304975851293"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db1e93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance very bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5512f4df",
   "metadata": {},
   "source": [
    "# ANN2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc91e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6665 - val_loss: 0.6641\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5685 - val_loss: 0.5961\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5200 - val_loss: 0.5476\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4776 - val_loss: 0.5015\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4358 - val_loss: 0.4557\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3941 - val_loss: 0.4090\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3512 - val_loss: 0.3615\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3077 - val_loss: 0.3127\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2632 - val_loss: 0.2639\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2194 - val_loss: 0.2162\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1777 - val_loss: 0.1707\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1378 - val_loss: 0.1299\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1028 - val_loss: 0.0948\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0737 - val_loss: 0.0663\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0506 - val_loss: 0.0452\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0345 - val_loss: 0.0308\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0222\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0085\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0077\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0070\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "\n",
    "model2.add(Dense(7,activation='relu',input_dim=7))\n",
    "model2.add(Dense(7,activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))\n",
    "model2.compile(loss='mean_squared_error',optimizer='Adam')\n",
    "history2=model2.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69f927",
   "metadata": {},
   "source": [
    "# ANN2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a179d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5188873 ],\n",
       "       [0.6659118 ],\n",
       "       [0.835534  ],\n",
       "       [0.71761537],\n",
       "       [0.8365697 ],\n",
       "       [0.69366145],\n",
       "       [0.7546654 ],\n",
       "       [0.8266283 ],\n",
       "       [0.78284216],\n",
       "       [0.75340486],\n",
       "       [0.6980239 ],\n",
       "       [0.6478362 ],\n",
       "       [0.81647915],\n",
       "       [0.6570984 ],\n",
       "       [0.7510974 ],\n",
       "       [0.9271177 ],\n",
       "       [0.6229254 ],\n",
       "       [0.69224334],\n",
       "       [0.82813156],\n",
       "       [0.5926377 ],\n",
       "       [0.665564  ],\n",
       "       [0.8281687 ],\n",
       "       [0.86204857],\n",
       "       [0.72695875],\n",
       "       [0.72619045],\n",
       "       [0.5457321 ],\n",
       "       [0.9617225 ],\n",
       "       [0.6079456 ],\n",
       "       [0.8561928 ],\n",
       "       [0.66046304],\n",
       "       [0.6303814 ],\n",
       "       [0.77216995],\n",
       "       [0.64426625],\n",
       "       [0.8924584 ],\n",
       "       [0.5110881 ],\n",
       "       [0.732515  ],\n",
       "       [0.673588  ],\n",
       "       [0.6222898 ],\n",
       "       [0.62771624],\n",
       "       [0.8248447 ],\n",
       "       [0.50078994],\n",
       "       [0.7150674 ],\n",
       "       [0.90847945],\n",
       "       [0.9230262 ],\n",
       "       [0.72041065],\n",
       "       [0.45534134],\n",
       "       [0.6280288 ],\n",
       "       [0.60365856],\n",
       "       [0.6850925 ],\n",
       "       [0.67077106],\n",
       "       [0.8510314 ],\n",
       "       [0.9261351 ],\n",
       "       [0.79100007],\n",
       "       [0.6599667 ],\n",
       "       [0.82233256],\n",
       "       [0.6172222 ],\n",
       "       [0.78442645],\n",
       "       [0.53503424],\n",
       "       [0.69964486],\n",
       "       [0.72261584],\n",
       "       [0.3642164 ],\n",
       "       [0.7600915 ],\n",
       "       [0.90971434],\n",
       "       [0.77433074],\n",
       "       [0.9768114 ],\n",
       "       [0.5933513 ],\n",
       "       [0.7775496 ],\n",
       "       [0.83395135],\n",
       "       [0.9568304 ],\n",
       "       [0.6357935 ],\n",
       "       [0.54723585],\n",
       "       [0.60275936],\n",
       "       [0.7185033 ],\n",
       "       [0.50015193],\n",
       "       [0.9032881 ],\n",
       "       [0.57751524],\n",
       "       [0.88888854],\n",
       "       [0.9340708 ],\n",
       "       [0.67441964],\n",
       "       [0.7742885 ],\n",
       "       [0.84147954],\n",
       "       [0.48765337],\n",
       "       [0.8418875 ],\n",
       "       [0.88232344],\n",
       "       [0.8018829 ],\n",
       "       [0.67472833],\n",
       "       [0.91362727],\n",
       "       [0.8571484 ],\n",
       "       [0.64911586],\n",
       "       [0.50268644],\n",
       "       [0.5426451 ],\n",
       "       [0.81857944],\n",
       "       [0.5469767 ],\n",
       "       [0.76374346],\n",
       "       [0.69125044],\n",
       "       [0.87266403],\n",
       "       [0.8252459 ],\n",
       "       [0.60660636],\n",
       "       [0.7229074 ],\n",
       "       [0.62539715]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2=model2.predict(X_test_scaled)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d82393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304    0.62\n",
       "340    0.75\n",
       "47     0.89\n",
       "67     0.57\n",
       "479    0.79\n",
       "       ... \n",
       "11     0.84\n",
       "192    0.86\n",
       "92     0.34\n",
       "221    0.75\n",
       "110    0.61\n",
       "Name: Chance of Admit , Length: 100, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a804d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048206883235015"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af61a9",
   "metadata": {},
   "source": [
    "\n",
    "# plot loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3b4e6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1781dde1110>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history2.history['loss'])#blue\n",
    "plt.plot(history2.history['val_loss'])#orange\n",
    "#as u see at epochs loss decreasing ,,,both val_loss and loss are same ,,so model is not overfitted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
